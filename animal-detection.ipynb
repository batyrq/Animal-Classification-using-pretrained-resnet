{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2197760,"sourceType":"datasetVersion","datasetId":1316317}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset\n\nclass ImageDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n\n        self.image_paths = []\n        self.labels = []\n\n        self.class_names = sorted(os.listdir(root_dir))\n        self.class_to_idx = {name: idx for idx, name in enumerate(self.class_names)}\n        print(self.class_to_idx)  # {'bear': 0, 'deer': 1, 'dog': 2, ...}\n\n        for class_name in self.class_names:\n            class_dir = os.path.join(root_dir, class_name)\n            if not os.path.isdir(class_dir):\n                continue\n\n            for file in os.listdir(class_dir):\n                if file.endswith(('.jpg', '.jpeg', '.png')):\n                    self.image_paths.append(os.path.join(class_dir, file))\n                    self.labels.append(self.class_to_idx[class_name])\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T15:42:09.808383Z","iopub.execute_input":"2025-06-11T15:42:09.808664Z","iopub.status.idle":"2025-06-11T15:42:12.153059Z","shell.execute_reply.started":"2025-06-11T15:42:09.808640Z","shell.execute_reply":"2025-06-11T15:42:12.152107Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Subset\n\ntransform_train = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n])\n\n\ndataset = ImageDataset('/kaggle/input/animals-detection-images-dataset/train', transform=transform_train)\n\ntrain_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=0.2, stratify=dataset.labels)\ntrain_dataset = Subset(dataset, train_idx)\nval_dataset = Subset(dataset, val_idx)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T15:42:12.159588Z","iopub.execute_input":"2025-06-11T15:42:12.159925Z","iopub.status.idle":"2025-06-11T15:42:14.815033Z","shell.execute_reply.started":"2025-06-11T15:42:12.159898Z","shell.execute_reply":"2025-06-11T15:42:14.813952Z"}},"outputs":[{"name":"stdout","text":"{'Bear': 0, 'Brown bear': 1, 'Bull': 2, 'Butterfly': 3, 'Camel': 4, 'Canary': 5, 'Caterpillar': 6, 'Cattle': 7, 'Centipede': 8, 'Cheetah': 9, 'Chicken': 10, 'Crab': 11, 'Crocodile': 12, 'Deer': 13, 'Duck': 14, 'Eagle': 15, 'Elephant': 16, 'Fish': 17, 'Fox': 18, 'Frog': 19, 'Giraffe': 20, 'Goat': 21, 'Goldfish': 22, 'Goose': 23, 'Hamster': 24, 'Harbor seal': 25, 'Hedgehog': 26, 'Hippopotamus': 27, 'Horse': 28, 'Jaguar': 29, 'Jellyfish': 30, 'Kangaroo': 31, 'Koala': 32, 'Ladybug': 33, 'Leopard': 34, 'Lion': 35, 'Lizard': 36, 'Lynx': 37, 'Magpie': 38, 'Monkey': 39, 'Moths and butterflies': 40, 'Mouse': 41, 'Mule': 42, 'Ostrich': 43, 'Otter': 44, 'Owl': 45, 'Panda': 46, 'Parrot': 47, 'Penguin': 48, 'Pig': 49, 'Polar bear': 50, 'Rabbit': 51, 'Raccoon': 52, 'Raven': 53, 'Red panda': 54, 'Rhinoceros': 55, 'Scorpion': 56, 'Sea lion': 57, 'Sea turtle': 58, 'Seahorse': 59, 'Shark': 60, 'Sheep': 61, 'Shrimp': 62, 'Snail': 63, 'Snake': 64, 'Sparrow': 65, 'Spider': 66, 'Squid': 67, 'Squirrel': 68, 'Starfish': 69, 'Swan': 70, 'Tick': 71, 'Tiger': 72, 'Tortoise': 73, 'Turkey': 74, 'Turtle': 75, 'Whale': 76, 'Woodpecker': 77, 'Worm': 78, 'Zebra': 79}\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T15:42:14.819884Z","iopub.execute_input":"2025-06-11T15:42:14.820639Z","iopub.status.idle":"2025-06-11T15:42:14.827046Z","shell.execute_reply.started":"2025-06-11T15:42:14.820577Z","shell.execute_reply":"2025-06-11T15:42:14.825379Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nnum_classes = len(dataset.class_to_idx)\n\nfrom torchvision.models import resnet18\n\nmodel = resnet18(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T15:46:28.470823Z","iopub.execute_input":"2025-06-11T15:46:28.471339Z","iopub.status.idle":"2025-06-11T15:46:28.724858Z","shell.execute_reply.started":"2025-06-11T15:46:28.471306Z","shell.execute_reply":"2025-06-11T15:46:28.723453Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"for epoch in range(10):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n    acc = 100. * correct / total\n    print(f\"Epoch {epoch+1} | Loss: {running_loss:.4f} | Train Acc: {acc:.2f}%\")\n\n    # Валидация\n    model.eval()\n    val_correct = 0\n    val_total = 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = outputs.max(1)\n            val_total += labels.size(0)\n            val_correct += predicted.eq(labels).sum().item()\n    val_acc = 100. * val_correct / val_total\n    print(f\"Validation Acc: {val_acc:.2f}%\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T15:46:33.811639Z","iopub.execute_input":"2025-06-11T15:46:33.812210Z","iopub.status.idle":"2025-06-11T19:27:28.633222Z","shell.execute_reply.started":"2025-06-11T15:46:33.812169Z","shell.execute_reply":"2025-06-11T19:27:28.628067Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 | Loss: 1633.2952 | Train Acc: 28.53%\nValidation Acc: 33.25%\n\nEpoch 2 | Loss: 1264.8941 | Train Acc: 40.82%\nValidation Acc: 39.70%\n\nEpoch 3 | Loss: 1100.5082 | Train Acc: 46.96%\nValidation Acc: 46.37%\n\nEpoch 4 | Loss: 956.6294 | Train Acc: 52.53%\nValidation Acc: 46.68%\n\nEpoch 5 | Loss: 838.4260 | Train Acc: 57.64%\nValidation Acc: 48.54%\n\nEpoch 6 | Loss: 756.8016 | Train Acc: 60.95%\nValidation Acc: 51.60%\n\nEpoch 7 | Loss: 685.9907 | Train Acc: 63.98%\nValidation Acc: 49.67%\n\nEpoch 8 | Loss: 596.5497 | Train Acc: 67.99%\nValidation Acc: 49.69%\n\nEpoch 9 | Loss: 542.5117 | Train Acc: 70.58%\nValidation Acc: 52.70%\n\nEpoch 10 | Loss: 478.2218 | Train Acc: 73.52%\nValidation Acc: 51.84%\n\n","output_type":"stream"}],"execution_count":8}]}